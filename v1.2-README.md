# UmukoziHR Resume Tailor v1.2 ğŸš€

Scale-ready upgrade with authentication, database storage, and background processing capabilities.

## ğŸ†• What's New in v1.2

- **User Authentication**: JWT-based signup/login system
- **Database Storage**: PostgreSQL for user data and job tracking  
- **Background Processing**: Celery/Redis queue system (optional)
- **Cloud Storage**: S3 integration for artifacts (optional)
- **Backward Compatibility**: Works without auth for existing users

## ğŸ—ï¸ Architecture

```
Frontend (Next.js) â†’ API (FastAPI) â†’ Database (PostgreSQL)
                                   â†“
                              Queue (Celery/Redis) â†’ S3 Storage
```

## ğŸš€ Quick Start

### 1. Prerequisites
- PostgreSQL running locally
- Python 3.8+
- Node.js 18+ (for frontend)

### 2. Backend Setup

```bash
cd server
pip install -r requirements.txt
cp .env.example .env
# Edit .env with your database credentials and API keys
python start.py
```

### 3. Frontend Setup (optional)

```bash
cd client
pnpm install
pnpm dev
```

## ğŸ“š API Endpoints

### Authentication (New!)
- `POST /api/v1/auth/signup` - Create account
- `POST /api/v1/auth/login` - Login

### Generation (Updated)
- `POST /api/v1/generate/generate` - Generate documents (auth optional)
- `GET /api/v1/generate/status/{run_id}` - Check status (auth required)

### Profile Management
- `POST /api/v1/profile/save` - Save profile
- `GET /api/v1/profile/load` - Load profile

## ğŸ”§ Configuration

### Environment Variables (.env)

```bash
# Database (Required)
DATABASE_URL=postgresql://user:pass@localhost/umukozihr

# Auth (Required)
SECRET_KEY=your-secret-key-change-in-production

# AI (Required)
GEMINI_API_KEY=your-gemini-api-key

# Queue (Optional - fallback to sync processing)
REDIS_URL=redis://localhost:6379/0

# S3 (Optional - fallback to local storage)
AWS_ACCESS_KEY_ID=your-key
AWS_SECRET_ACCESS_KEY=your-secret
S3_BUCKET=your-bucket
```

## ğŸ”„ Migration from v1.1

Your existing v1.1 installation will continue to work! 

- **Without auth**: Same API behavior as v1.1
- **With auth**: Enhanced features like job tracking and status checking

## ğŸ¯ Usage Examples

### Without Authentication (v1.1 compatibility)
```javascript
// Same as before - just send the generate request
const response = await fetch('/api/v1/generate/generate', {
  method: 'POST',
  body: JSON.stringify({profile, jobs})
});
```

### With Authentication (New v1.2 features)
```javascript
// 1. Login
const login = await fetch('/api/v1/auth/login', {
  method: 'POST',
  body: JSON.stringify({email, password})
});
const {access_token} = await login.json();

// 2. Generate with tracking
const generate = await fetch('/api/v1/generate/generate', {
  method: 'POST',
  headers: {Authorization: `Bearer ${access_token}`},
  body: JSON.stringify({profile, jobs})
});
const {run_id} = await generate.json();

// 3. Check status
const status = await fetch(`/api/v1/generate/status/${run_id}`, {
  headers: {Authorization: `Bearer ${access_token}`}
});
```

## ğŸƒâ€â™‚ï¸ Deployment Options

### Development
```bash
python start.py  # Handles migration + starts server
```

### Production with Docker
```bash
docker-compose up  # Full stack with PostgreSQL + Redis
```

### Production Manual
```bash
# Setup database
python migrate.py

# Start API server
uvicorn app.main:app --host 0.0.0.0 --port 8000

# Start background worker (optional)
celery -A app.queue.tasks worker --loglevel=info
```

## ğŸ”’ Security Notes

- Change `SECRET_KEY` in production
- Use environment variables for sensitive data
- Enable HTTPS in production
- Consider rate limiting for public APIs

## ğŸ› Troubleshooting

### Database Connection Issues
```bash
# Check PostgreSQL is running
pg_isready

# Test connection
python -c "from app.db.database import engine; engine.connect()"
```

### Migration Issues
```bash
# Reset database (dev only!)
python -c "from app.db.database import Base, engine; Base.metadata.drop_all(engine)"
python migrate.py
```

### Queue Not Working
- Redis is optional - system falls back to sync processing
- Check Redis: `redis-cli ping`
- Start worker: `celery -A app.queue.tasks worker`

## ğŸ“ˆ Scaling Considerations

### Current Setup (v1.2)
- Synchronous processing for all users
- Local file storage
- Single server deployment

### Future Enhancements
- Enable Celery workers for background processing
- S3 for distributed file storage  
- Load balancer for multiple API servers
- Database read replicas for analytics

---

**Status**: âœ… Ready for production
**Migration**: ğŸ”„ Backward compatible with v1.1
**Queue**: ğŸ”§ Optional (Celery/Redis)
**Storage**: ğŸ“ Local + S3 ready