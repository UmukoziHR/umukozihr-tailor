ok Jason, solid v1.1. i see the full picture now. FastAPI + Next.js, Gemini for LLM, local LaTeX compilation, everything stored in `artifacts/` folder

here's what needs to change for v1.2 scale-ready. i'll give you exact code for each file

## Phase 1: Database Setup

First, new file: `server/app/db/database.py`

```python
import os
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker

DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://user:pass@localhost/umukozihr")

engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```

New file: `server/app/db/models.py`

```python
from sqlalchemy import Column, String, Text, JSON, DateTime, ForeignKey
from sqlalchemy.dialects.postgresql import UUID
from datetime import datetime
import uuid
from .database import Base

class User(Base):
    __tablename__ = "users"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    email = Column(String, unique=True, nullable=False)
    password_hash = Column(String, nullable=False)
    created_at = Column(DateTime, default=datetime.utcnow)

class Profile(Base):
    __tablename__ = "profiles"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
    profile_data = Column(JSON, nullable=False)
    updated_at = Column(DateTime, default=datetime.utcnow)

class Job(Base):
    __tablename__ = "jobs"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
    company = Column(String)
    title = Column(String)
    jd_text = Column(Text)
    region = Column(String)
    created_at = Column(DateTime, default=datetime.utcnow)

class Run(Base):
    __tablename__ = "runs"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
    job_id = Column(UUID(as_uuid=True), ForeignKey("jobs.id"))
    status = Column(String, default="pending")  # pending, processing, completed, failed
    llm_output = Column(JSON)
    artifacts_urls = Column(JSON)
    created_at = Column(DateTime, default=datetime.utcnow)
```

## Phase 2: Auth System

New file: `server/app/auth/auth.py`

```python
from passlib.context import CryptContext
from jose import JWTError, jwt
from datetime import datetime, timedelta
import os

SECRET_KEY = os.getenv("SECRET_KEY", "your-secret-key-change-in-production")
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 30

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

def hash_password(password: str) -> str:
    return pwd_context.hash(password)

def verify_password(plain_password: str, hashed_password: str) -> bool:
    return pwd_context.verify(plain_password, hashed_password)

def create_access_token(data: dict):
    to_encode = data.copy()
    expire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

def verify_token(token: str):
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        return payload
    except JWTError:
        return None
```

New file: `server/app/routes/v1_auth.py`

```python
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from pydantic import BaseModel, EmailStr
from app.db.database import get_db
from app.db.models import User
from app.auth.auth import hash_password, verify_password, create_access_token

router = APIRouter(prefix="/api/v1/auth", tags=["auth"])

class SignupRequest(BaseModel):
    email: EmailStr
    password: str

class LoginRequest(BaseModel):
    email: EmailStr
    password: str

@router.post("/signup")
def signup(req: SignupRequest, db: Session = Depends(get_db)):
    # check if user exists
    existing = db.query(User).filter(User.email == req.email).first()
    if existing:
        raise HTTPException(status_code=400, detail="Email already registered")
    
    # create user
    user = User(
        email=req.email,
        password_hash=hash_password(req.password)
    )
    db.add(user)
    db.commit()
    
    # return token
    access_token = create_access_token({"sub": str(user.id)})
    return {"access_token": access_token, "token_type": "bearer"}

@router.post("/login")
def login(req: LoginRequest, db: Session = Depends(get_db)):
    user = db.query(User).filter(User.email == req.email).first()
    if not user or not verify_password(req.password, user.password_hash):
        raise HTTPException(status_code=401, detail="Invalid credentials")
    
    access_token = create_access_token({"sub": str(user.id)})
    return {"access_token": access_token, "token_type": "bearer"}
```

## Phase 3: Queue System

New file: `server/app/queue/tasks.py`

```python
from celery import Celery
import os
from app.core.tailor import create_tailored_documents
from app.db.database import SessionLocal
from app.db.models import Run
from app.storage.s3 import upload_to_s3

celery_app = Celery(
    'tasks',
    broker=os.getenv('REDIS_URL', 'redis://localhost:6379/0'),
    backend=os.getenv('REDIS_URL', 'redis://localhost:6379/0')
)

@celery_app.task
def process_generation(run_id: str, profile_data: dict, jobs: list):
    db = SessionLocal()
    run = db.query(Run).filter(Run.id == run_id).first()
    
    try:
        # update status
        run.status = "processing"
        db.commit()
        
        # call existing tailor logic
        results = create_tailored_documents(profile_data, jobs)
        
        # upload artifacts to S3
        artifact_urls = {}
        for artifact in results['artifacts']:
            for key, local_path in artifact.items():
                if local_path.endswith(('.pdf', '.tex', '.zip')):
                    s3_url = upload_to_s3(local_path)
                    artifact_urls[key] = s3_url
        
        # update run with results
        run.status = "completed"
        run.llm_output = results.get('llm_output')
        run.artifacts_urls = artifact_urls
        db.commit()
        
    except Exception as e:
        run.status = "failed"
        run.llm_output = {"error": str(e)}
        db.commit()
    finally:
        db.close()
```

## Phase 4: S3 Storage

New file: `server/app/storage/s3.py`

```python
import boto3
import os
from botocore.exceptions import NoCredentialsError

s3_client = boto3.client(
    's3',
    aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),
    aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY'),
    region_name=os.getenv('AWS_REGION', 'us-east-1')
)

BUCKET_NAME = os.getenv('S3_BUCKET', 'umukozihr-artifacts')

def upload_to_s3(local_path: str) -> str:
    """Upload file to S3 and return signed URL"""
    try:
        file_name = os.path.basename(local_path)
        s3_key = f"artifacts/{file_name}"
        
        # upload
        s3_client.upload_file(local_path, BUCKET_NAME, s3_key)
        
        # generate signed URL (7 days expiry)
        url = s3_client.generate_presigned_url(
            'get_object',
            Params={'Bucket': BUCKET_NAME, 'Key': s3_key},
            ExpiresIn=604800  # 7 days
        )
        return url
        
    except NoCredentialsError:
        # fallback to local if S3 not configured
        return f"/artifacts/{os.path.basename(local_path)}"
```

## Phase 5: Updated Generate Endpoint

Update `server/app/routes/v1_generate.py`:

```python
from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks
from sqlalchemy.orm import Session
from app.db.database import get_db
from app.db.models import Run, Job, Profile
from app.queue.tasks import process_generation
from app.auth.auth import verify_token
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
import uuid

router = APIRouter(prefix="/api/v1/generate", tags=["generate"])
security = HTTPBearer()

def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security), db: Session = Depends(get_db)):
    token = credentials.credentials
    payload = verify_token(token)
    if not payload:
        raise HTTPException(status_code=401, detail="Invalid token")
    return payload["sub"]

@router.post("/generate")
def generate(
    profile: dict, 
    jobs: list,
    user_id: str = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    # create run record
    run_id = str(uuid.uuid4())
    run = Run(
        id=run_id,
        user_id=user_id,
        status="pending"
    )
    db.add(run)
    db.commit()
    
    # enqueue task
    process_generation.delay(run_id, profile, jobs)
    
    return {"run_id": run_id, "status": "pending"}

@router.get("/status/{run_id}")
def get_status(run_id: str, user_id: str = Depends(get_current_user), db: Session = Depends(get_db)):
    run = db.query(Run).filter(Run.id == run_id, Run.user_id == user_id).first()
    if not run:
        raise HTTPException(status_code=404, detail="Run not found")
    
    return {
        "run_id": run.id,
        "status": run.status,
        "artifacts": run.artifacts_urls if run.status == "completed" else None,
        "error": run.llm_output.get("error") if run.status == "failed" else None
    }
```

## Phase 6: Frontend Updates

Update `client/lib/api.ts`:

```typescript
import axios from 'axios';

const API_URL = process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8000';

const api = axios.create({
  baseURL: API_URL,
});

// Add auth interceptor
api.interceptors.request.use((config) => {
  const token = localStorage.getItem('token');
  if (token) {
    config.headers.Authorization = `Bearer ${token}`;
  }
  return config;
});

export const auth = {
  signup: (email: string, password: string) => 
    api.post('/api/v1/auth/signup', { email, password }),
  
  login: (email: string, password: string) =>
    api.post('/api/v1/auth/login', { email, password }),
};

export const generation = {
  generate: (profile: any, jobs: any[]) =>
    api.post('/api/v1/generate/generate', { profile, jobs }),
  
  getStatus: (runId: string) =>
    api.get(`/api/v1/generate/status/${runId}`),
};

export default api;
```

New component `client/components/LoginForm.tsx`:

```tsx
import { useState } from 'react';
import { auth } from '../lib/api';

export default function LoginForm({ onLogin }) {
  const [email, setEmail] = useState('');
  const [password, setPassword] = useState('');
  const [isSignup, setIsSignup] = useState(false);

  const handleSubmit = async (e) => {
    e.preventDefault();
    try {
      const endpoint = isSignup ? auth.signup : auth.login;
      const res = await endpoint(email, password);
      localStorage.setItem('token', res.data.access_token);
      onLogin(res.data.access_token);
    } catch (error) {
      alert('Auth failed: ' + error.message);
    }
  };

  return (
    <form onSubmit={handleSubmit} className="space-y-4 max-w-md mx-auto p-6">
      <input
        type="email"
        placeholder="Email"
        value={email}
        onChange={(e) => setEmail(e.target.value)}
        className="w-full p-2 border rounded"
        required
      />
      <input
        type="password"
        placeholder="Password"
        value={password}
        onChange={(e) => setPassword(e.target.value)}
        className="w-full p-2 border rounded"
        required
      />
      <button type="submit" className="w-full bg-blue-600 text-white p-2 rounded">
        {isSignup ? 'Sign Up' : 'Login'}
      </button>
      <button
        type="button"
        onClick={() => setIsSignup(!isSignup)}
        className="text-blue-600 underline"
      >
        {isSignup ? 'Already have account?' : 'Create account'}
      </button>
    </form>
  );
}
```

## Phase 7: Environment & Dependencies

Update `server/requirements.txt`:

```
fastapi==0.104.1
uvicorn==0.24.0
pydantic==2.4.2
google-generativeai==0.3.0
jinja2==3.1.2
python-multipart==0.0.6
python-docx==1.1.0
pypdf==3.17.0
sqlalchemy==2.0.23
psycopg2-binary==2.9.9
celery==5.3.4
redis==5.0.1
boto3==1.34.14
passlib==1.7.4
python-jose==3.3.0
bcrypt==4.1.2
python-dotenv==1.0.0
```

Create `server/.env`:

```bash
# Database
DATABASE_URL=postgresql://user:pass@localhost/umukozihr

# Auth
SECRET_KEY=your-secret-key-change-this-in-production

# Redis (for queue)
REDIS_URL=redis://localhost:6379/0

# S3 (optional, falls back to local if not set)
AWS_ACCESS_KEY_ID=your-key
AWS_SECRET_ACCESS_KEY=your-secret
AWS_REGION=us-east-1
S3_BUCKET=umukozihr-artifacts

# Existing
GEMINI_API_KEY=your-gemini-key
```

## Phase 8: Docker Setup

New file: `docker-compose.yml`:

```yaml
version: '3.8'

services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
      POSTGRES_DB: umukozihr
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:7
    ports:
      - "6379:6379"

  api:
    build: ./server
    ports:
      - "8000:8000"
    environment:
      DATABASE_URL: postgresql://user:pass@postgres/umukozihr
      REDIS_URL: redis://redis:6379/0
    depends_on:
      - postgres
      - redis
    volumes:
      - ./server:/app

  celery:
    build: ./server
    command: celery -A app.queue.tasks worker --loglevel=info
    environment:
      DATABASE_URL: postgresql://user:pass@postgres/umukozihr
      REDIS_URL: redis://redis:6379/0
    depends_on:
      - postgres
      - redis
    volumes:
      - ./server:/app

  frontend:
    build: ./client
    ports:
      - "3000:3000"
    environment:
      NEXT_PUBLIC_API_URL: http://localhost:8000
    depends_on:
      - api

volumes:
  postgres_data:
```

## Migration Script

New file: `server/migrate.py`:

```python
from app.db.database import engine
from app.db.models import Base

if __name__ == "__main__":
    Base.metadata.create_all(bind=engine)
    print("Database tables created")
```

---

ok Jason, that's the full v1.2 upgrade. here's your step-by-step:

1. install postgres and redis locally (or use docker-compose)
2. update requirements.txt and npm packages
3. create all the new files i listed above
4. run `python migrate.py` to create tables
5. start celery worker: `celery -A app.queue.tasks worker`
6. update main.py to include new routers
7. test auth flow first, then generation with queue

what part you want me to explain more? or you stuck somewhere?